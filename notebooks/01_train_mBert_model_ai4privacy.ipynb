{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rqyB2LPcrRI"
      },
      "source": [
        "# Training a BERT Model for PII Detection\n",
        "\n",
        "This notebook walks through the complete process of training a multilingual BERT model to automatically identify personally identifiable information (PII) in text. We'll use a large dataset of 400,000 examples to teach the model to recognize things like names, emails, phone numbers, addresses, and other sensitive information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiFJfVOrcrRJ"
      },
      "source": [
        "## Setting Up the Environment and Loading Data\n",
        "\n",
        "First, we need to install the required libraries and load our dataset. We're installing the Hugging Face transformers library (which gives us access to BERT), along with tools for evaluation and data handling.\n",
        "\n",
        "The dataset we're using comes from ai4privacy and contains 400,000 text examples where PII has already been labeled. This means someone has gone through and marked exactly where names, emails, and other sensitive info appear in each text. We'll use these labels to teach our model what PII looks like.\n",
        "\n",
        "We're using \"bert-base-multilingual-cased\" as our starting point. This is a pre-trained model that already understands multiple languages, which we'll fine-tune specifically for detecting PII."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mnZHRps0tx-G",
        "outputId": "fda0f6c5-48f5-43aa-986f-0dcbc2401d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n",
        "!pip install -U transformers accelerate evaluate seqeval datasets\n",
        "\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import (AutoTokenizer, AutoModelForTokenClassification,\n",
        "                          DataCollatorForTokenClassification, TrainingArguments,\n",
        "                          Trainer)\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "ds = load_dataset(\"ai4privacy/pii-masking-400k\")  # has train and validation\n",
        "train_ds = ds[\"train\"]\n",
        "val_ds   = ds[\"validation\"]\n",
        "\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea8l6jCqcrRL"
      },
      "source": [
        "## Checking the Transformers Version\n",
        "\n",
        "Quick check to see which version of the transformers library we have installed. Different versions might have slightly different features or options available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEEC_1xPTir9",
        "outputId": "d371a0eb-404e-441d-d957-1194c3d5b90d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.57.1\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1iMWe_lcrRL"
      },
      "source": [
        "## Exploring the Dataset Structure\n",
        "\n",
        "Let's take a look at what columns our dataset has. This helps us understand what information is available and how the data is organized. We need to know the column names so we can access the pre-tokenized text and labels correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKP1cqYGfLu3",
        "outputId": "a73dc7ee-1a58-42a9-a305-1749c091ade8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['source_text', 'locale', 'language', 'split', 'privacy_mask', 'uid', 'masked_text', 'mbert_tokens', 'mbert_token_classes']\n"
          ]
        }
      ],
      "source": [
        "print(train_ds.column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z1KkJ7ocrRM"
      },
      "source": [
        "## Setting Up Column Names\n",
        "\n",
        "Here we're just defining which columns in our dataset contain the tokens (small chunks of text) and their corresponding labels. This makes the code easier to read and modify later if the dataset structure changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1TF1oAtoyXi"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2gG3lVEQzTc"
      },
      "outputs": [],
      "source": [
        "TOK_COL = \"mbert_tokens\"\n",
        "LAB_COL = \"mbert_token_classes\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR-B5qUvcrRN"
      },
      "source": [
        "## Building Label Mappings and Preparing Data\n",
        "\n",
        "This is where we prepare the data for training. We're doing several important things here:\n",
        "\n",
        "1. **Creating label mappings**: We collect all the unique labels from our dataset (like \"B-EMAIL\", \"I-EMAIL\", \"O\", etc.) and assign each one a number. The model works with numbers, not text labels, so we need these mappings to convert back and forth.\n",
        "\n",
        "2. **Understanding tokens and labels**: Think of tokens as individual words or word pieces. For example, \"kevin@email.com\" might be split into several tokens. Each token needs a label telling the model what type of information it is (or \"O\" if it's not PII).\n",
        "\n",
        "3. **Encoding the data**: The `encode_batch` function takes our text tokens and converts them into the format BERT expects. It also aligns the labels properly so each token has the correct label. Some special tokens (like padding) get a label of -100, which tells the model to ignore them during training.\n",
        "\n",
        "4. **Processing the dataset**: We apply this encoding to all our training and validation examples, transforming them into a format ready for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "fe33df3b873845c986d5c0da6c26c1ab",
            "474acc82aab24f02b52c1238101177aa",
            "da3cc5ab24a845f5841507f66db663c1",
            "2df8bfc7ef894bc0b0665334c35a8f72",
            "d293c16207de440699028c2907416c4f",
            "a5d219a6b02f42e9a6d6899dc5b5df86",
            "24ebeaf171d0441a95587b23059c1578",
            "c222e16d7c2a48e4a45e11cc4d7a929d",
            "b9125e6aa1e7462cb5ef0c4a54bfebc8",
            "769bed9cc3574b57b5e9e801894f2155",
            "98a87f15420f4bb9a01a6710369751fa"
          ]
        },
        "id": "o6Zxi7YaRhQ2",
        "outputId": "ea350def-6a7c-417e-8e91-ae3b8838d7c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels: ['O', 'B-ACCOUNTNUM', 'B-BUILDINGNUM', 'B-CITY', 'B-CREDITCARDNUMBER', 'B-DATEOFBIRTH', 'B-DRIVERLICENSENUM', 'B-EMAIL', 'B-GIVENNAME', 'B-IDCARDNUM', 'B-PASSWORD', 'B-SOCIALNUM', 'B-STREET', 'B-SURNAME', 'B-TAXNUM', 'B-TELEPHONENUM', 'B-USERNAME', 'B-ZIPCODE', 'I-ACCOUNTNUM', 'I-BUILDINGNUM', 'I-CITY', 'I-CREDITCARDNUMBER', 'I-DATEOFBIRTH', 'I-DRIVERLICENSENUM', 'I-EMAIL', 'I-GIVENNAME', 'I-IDCARDNUM', 'I-PASSWORD', 'I-SOCIALNUM', 'I-STREET', 'I-SURNAME', 'I-TAXNUM', 'I-TELEPHONENUM', 'I-USERNAME', 'I-ZIPCODE']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe33df3b873845c986d5c0da6c26c1ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/81379 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build label list directly from the dataset's BIO labels\n",
        "label_set = set()\n",
        "for ex in train_ds[LAB_COL]:\n",
        "    label_set.update(ex)\n",
        "# Ensure \"O\" is first\n",
        "label_list = [\"O\"] + sorted([lab for lab in label_set if lab != \"O\"])\n",
        "label2id = {lab: i for i, lab in enumerate(label_list)}\n",
        "id2label = {i: lab for lab, i in label2id.items()}\n",
        "# LAB_COL is a column where each row is a list of BIO tags, e.g. [\"O\", B-EMAIL, I-EMAIL, ..], one tage per token\n",
        "# In short a token is just a small chunk of text that the model sees as one unit, e.g. [\"my\" \"name\" \"is\" Kevin\"], each of these are tokens and are mapped to a integer id [1010, 2450, 2001, 12345, etc]\n",
        "# whats it moportant is that the model aligns labels to those tokens: so we want a label per token like: \"my\" -> O, \"name\" -> O, is -> O, kevin -> B-Name etc\n",
        "print(\"Labels:\", label_list)\n",
        "\n",
        "def encode_batch(examples):\n",
        "    batch_tokens = examples[TOK_COL]\n",
        "    batch_labels = examples[LAB_COL]\n",
        "\n",
        "    # Tokenize *tokens*, not raw text\n",
        "    enc = tokenizer(\n",
        "        batch_tokens,\n",
        "        is_split_into_words=True,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=False,\n",
        "    )\n",
        "\n",
        "    all_labels = []\n",
        "\n",
        "    # We need to get word_ids per example\n",
        "    # enc.word_ids(batch_index=i) returns a list of word indices for that example's tokens\n",
        "    for i in range(len(batch_tokens)):\n",
        "        word_ids = enc.word_ids(batch_index=i)\n",
        "        sent_labels = batch_labels[i]\n",
        "\n",
        "        tok_labels = []\n",
        "        for w_id in word_ids:\n",
        "            if w_id is None:\n",
        "                # Special tokens / padding ignore in loss\n",
        "                tok_labels.append(-100)\n",
        "            else:\n",
        "                tok_labels.append(label2id[sent_labels[w_id]])\n",
        "        all_labels.append(tok_labels)\n",
        "\n",
        "    enc[\"labels\"] = all_labels\n",
        "    return enc\n",
        "\n",
        "# Downsample\n",
        "MAX_TRAIN = len(train_ds)\n",
        "MAX_VAL   = len(val_ds)\n",
        "train_small = train_ds.select(range(min(MAX_TRAIN, len(train_ds))))\n",
        "val_small   = val_ds.select(range(min(MAX_VAL, len(val_ds))))\n",
        "encoded_train = train_small.map(\n",
        "    encode_batch,\n",
        "    batched=True,\n",
        "    remove_columns=train_small.column_names,\n",
        ")\n",
        "encoded_val = val_small.map(\n",
        "    encode_batch,\n",
        "    batched=True,\n",
        "    remove_columns=val_small.column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY9Iqhb2crRO"
      },
      "source": [
        "## Training the Model\n",
        "\n",
        "Now comes the main event - actually training our model. Here's what's happening:\n",
        "\n",
        "**Setting up the model**: We start with the pre-trained multilingual BERT and add a classification head on top. This head will learn to predict which label each token should have (is it a name? an email? just regular text?).\n",
        "\n",
        "**Evaluation metrics**: We're using seqeval, which is specifically designed for sequence labeling tasks like ours. It calculates precision (how many of our predictions are correct), recall (how many actual PII entities we found), and F1 score (a balance between the two).\n",
        "\n",
        "**Training configuration**: We set up parameters like:\n",
        "- Learning rate (how fast the model updates)\n",
        "- Batch size (how many examples to look at once)\n",
        "- Number of epochs (how many times to go through the entire dataset)\n",
        "- We enable FP16 (mixed precision training) if a GPU is available to speed things up\n",
        "\n",
        "**The training loop**: The Trainer handles all the complex stuff - feeding data to the model, calculating loss, updating weights, and periodically checking performance on the validation set. It saves checkpoints along the way and keeps the best performing model.\n",
        "\n",
        "After training finishes, we evaluate on the validation set one more time to see our final performance numbers, then save the trained model so we can use it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "SxWmDQ531Fd4",
        "outputId": "acc13c2a-f97e-420d-c13f-31eae2e2c7bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1215430486.py:68: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='122070' max='122070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [122070/122070 2:48:36, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.043500</td>\n",
              "      <td>0.038495</td>\n",
              "      <td>0.887051</td>\n",
              "      <td>0.895476</td>\n",
              "      <td>0.891244</td>\n",
              "      <td>0.987170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.018100</td>\n",
              "      <td>0.035619</td>\n",
              "      <td>0.906124</td>\n",
              "      <td>0.914934</td>\n",
              "      <td>0.910508</td>\n",
              "      <td>0.989060</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5087' max='5087' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5087/5087 04:53]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation metrics: {'eval_loss': 0.035619135946035385, 'eval_precision': 0.9061237697783927, 'eval_recall': 0.9149343698946538, 'eval_f1': 0.9105077562187103, 'eval_accuracy': 0.9890603846904966, 'eval_runtime': 369.3374, 'eval_samples_per_second': 220.338, 'eval_steps_per_second': 13.773, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('pii-detector-bert-mcased-news/best/tokenizer_config.json',\n",
              " 'pii-detector-bert-mcased-news/best/special_tokens_map.json',\n",
              " 'pii-detector-bert-mcased-news/best/vocab.txt',\n",
              " 'pii-detector-bert-mcased-news/best/added_tokens.json',\n",
              " 'pii-detector-bert-mcased-news/best/tokenizer.json')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from transformers import DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
        "import torch, numpy as np, evaluate\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(label_list),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "def compute_metrics(p):\n",
        "    preds  = np.argmax(p.predictions, axis=-1)\n",
        "    labels = p.label_ids\n",
        "\n",
        "    true_labels, true_preds = [], []\n",
        "    for pred_row, lab_row in zip(preds, labels):\n",
        "        cur_labels, cur_preds = [], []\n",
        "        for p_id, l_id in zip(pred_row, lab_row):\n",
        "            if l_id == -100:\n",
        "                continue\n",
        "            cur_labels.append(id2label[l_id])\n",
        "            cur_preds.append(id2label[p_id])\n",
        "        true_labels.append(cur_labels)\n",
        "        true_preds.append(cur_preds)\n",
        "\n",
        "    results = seqeval.compute(predictions=true_preds, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results.get(\"overall_precision\", 0.0),\n",
        "        \"recall\":    results.get(\"overall_recall\", 0.0),\n",
        "        \"f1\":        results.get(\"overall_f1\", 0.0),\n",
        "        \"accuracy\":  results.get(\"overall_accuracy\", 0.0),\n",
        "    }\n",
        "# Try adjusting number of epochs to check if there is a difference\n",
        "common_kwargs = dict(\n",
        "    output_dir=\"pii-detector-bert-mcased-news\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "try:\n",
        "    args = TrainingArguments(\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=3,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        **common_kwargs,\n",
        "    )\n",
        "except TypeError:\n",
        "    # If stuck on an older transformers version without these args\n",
        "    print(\"Older transformers version detected- falling back to step-based saving\")\n",
        "    args = TrainingArguments(\n",
        "        save_steps=10_000, # rare saves\n",
        "        output_dir=\"pii-detector-bert-mcased\",\n",
        "        **common_kwargs,\n",
        "    )\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=encoded_train,\n",
        "    eval_dataset=encoded_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "# If resuming from last checkpoint\n",
        "#last_ckpt = \"/content/pii-detector-bert-mcased-news/checkpoint-40690\"\n",
        "#trainer.train(resume_from_checkpoint=last_ckpt)\n",
        "trainer.train()\n",
        "eval_res = trainer.evaluate()\n",
        "print(\"Validation metrics:\", eval_res)\n",
        "trainer.save_model(\"pii-detector-bert-mcased-news/best\")\n",
        "tokenizer.save_pretrained(\"pii-detector-bert-mcased-news/best\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_erB7TtcrRO"
      },
      "source": [
        "## Getting Detailed Performance Metrics\n",
        "\n",
        "After training, we want to see detailed results broken down by entity type. This cell runs the model on the entire validation set and calculates metrics for each type of PII separately.\n",
        "\n",
        "We'll get to see not just overall performance, but specifically how well the model does at finding emails versus names versus phone numbers, etc. This helps us understand if the model struggles with certain types of information more than others.\n",
        "\n",
        "The seqeval library gives us comprehensive metrics including precision, recall, and F1 scores for each entity type, which is really helpful for understanding where the model excels and where it might need improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "SNjrmdl-aHYE",
        "outputId": "60270307-a3c6-417a-97d8-ffa7468017dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ACCOUNTNUM': {'precision': np.float64(0.8244444444444444), 'recall': np.float64(0.8381024096385542), 'f1': np.float64(0.8312173263629574), 'number': np.int64(3984)}, 'BUILDINGNUM': {'precision': np.float64(0.904), 'recall': np.float64(0.8781570913127948), 'f1': np.float64(0.8908911727439109), 'number': np.int64(3603)}, 'CITY': {'precision': np.float64(0.9247442766682903), 'recall': np.float64(0.9404334365325078), 'f1': np.float64(0.9325228710014122), 'number': np.int64(8075)}, 'CREDITCARDNUMBER': {'precision': np.float64(0.9096989966555183), 'recall': np.float64(0.9543859649122807), 'f1': np.float64(0.9315068493150684), 'number': np.int64(2565)}, 'DATEOFBIRTH': {'precision': np.float64(0.897063099738296), 'recall': np.float64(0.8220090594191314), 'f1': np.float64(0.8578976640711903), 'number': np.int64(3753)}, 'DRIVERLICENSENUM': {'precision': np.float64(0.9538834951456311), 'recall': np.float64(0.9504232164449818), 'f1': np.float64(0.9521502119927318), 'number': np.int64(2481)}, 'EMAIL': {'precision': np.float64(0.9976683937823834), 'recall': np.float64(0.9989623865110246), 'f1': np.float64(0.9983149708360337), 'number': np.int64(7710)}, 'GIVENNAME': {'precision': np.float64(0.8404270164666481), 'recall': np.float64(0.8924205378973105), 'f1': np.float64(0.8656437529196161), 'number': np.int64(13497)}, 'IDCARDNUM': {'precision': np.float64(0.8631745314969519), 'recall': np.float64(0.9283632831471588), 'f1': np.float64(0.8945828945828945), 'number': np.int64(4118)}, 'PASSWORD': {'precision': np.float64(0.9495481927710844), 'recall': np.float64(0.9578427649069502), 'f1': np.float64(0.9536774437511817), 'number': np.int64(2633)}, 'SOCIALNUM': {'precision': np.float64(0.8969943644333125), 'recall': np.float64(0.9442979564930785), 'f1': np.float64(0.9200385356454721), 'number': np.int64(3034)}, 'STREET': {'precision': np.float64(0.9337837837837838), 'recall': np.float64(0.9307650862068966), 'f1': np.float64(0.9322719913653534), 'number': np.int64(3712)}, 'SURNAME': {'precision': np.float64(0.8031442241968558), 'recall': np.float64(0.766721044045677), 'f1': np.float64(0.784510098481055), 'number': np.int64(9195)}, 'TAXNUM': {'precision': np.float64(0.9248031496062992), 'recall': np.float64(0.9027671022290545), 'f1': np.float64(0.9136522753792299), 'number': np.int64(2602)}, 'TELEPHONENUM': {'precision': np.float64(0.9948961633227736), 'recall': np.float64(0.9962989072964399), 'f1': np.float64(0.9955970412116943), 'number': np.int64(5674)}, 'USERNAME': {'precision': np.float64(0.9799695443364179), 'recall': np.float64(0.9772222871159911), 'f1': np.float64(0.9785939876008889), 'number': np.int64(8561)}, 'ZIPCODE': {'precision': np.float64(0.9188822571893651), 'recall': np.float64(0.9519392917369308), 'f1': np.float64(0.9351187189398122), 'number': np.int64(3558)}, 'overall_precision': np.float64(0.9061237697783927), 'overall_recall': np.float64(0.9149343698946538), 'overall_f1': np.float64(0.9105077562187103), 'overall_accuracy': 0.9890603846904966}\n"
          ]
        }
      ],
      "source": [
        "# Get raw predictions on val set\n",
        "preds_output = trainer.predict(encoded_val)\n",
        "preds = preds_output.predictions.argmax(-1)\n",
        "labels = preds_output.label_ids\n",
        "\n",
        "true_labels, true_preds = [], []\n",
        "for pred_row, lab_row in zip(preds, labels):\n",
        "    cur_labels, cur_preds = [], []\n",
        "    for p_id, l_id in zip(pred_row, lab_row):\n",
        "        if l_id == -100:\n",
        "            continue\n",
        "        cur_labels.append(id2label[l_id])\n",
        "        cur_preds.append(id2label[p_id])\n",
        "    true_labels.append(cur_labels)\n",
        "    true_preds.append(cur_preds)\n",
        "\n",
        "import evaluate\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "results = seqeval.compute(predictions=true_preds, references=true_labels)\n",
        "print(results)  # will include per-entity metrics too\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TXGZqhCcrRP"
      },
      "source": [
        "## Saving the Model (Optional)\n",
        "\n",
        "This section is for when you're working in Google Colab and want to download your trained model to your local computer. It zips up the model files and triggers a download.\n",
        "\n",
        "You only need to run this if you want to save the model locally. Otherwise, the model is already saved in the output directory and can be loaded from there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_v2rsHl1QDt"
      },
      "source": [
        "## No need to run unless you want to save models as zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qfqa4dJxuSy7",
        "outputId": "80561bdb-bf52-4967-c5c1-d2d23588a0cd"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_32bfc589-9d5f-4bdc-acbc-3b38dd5bcf19\", \"best.zip\", 659616136)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Point to your saved folder\n",
        "OUTPUT_DIR = \"/content/pii-detector-bert-mcased-news/best\"\n",
        "# Zip it into /content\n",
        "import shutil, os\n",
        "ZIP_BASENAME = \"/content/pii-detector-bert-mcased-news/best\"\n",
        "zip_path = shutil.make_archive(ZIP_BASENAME, \"zip\", OUTPUT_DIR)\n",
        "# Download to your desktop\n",
        "from google.colab import files\n",
        "files.download(zip_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24ebeaf171d0441a95587b23059c1578": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2df8bfc7ef894bc0b0665334c35a8f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_769bed9cc3574b57b5e9e801894f2155",
            "placeholder": "​",
            "style": "IPY_MODEL_98a87f15420f4bb9a01a6710369751fa",
            "value": " 81379/81379 [00:19&lt;00:00, 4585.80 examples/s]"
          }
        },
        "474acc82aab24f02b52c1238101177aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d219a6b02f42e9a6d6899dc5b5df86",
            "placeholder": "​",
            "style": "IPY_MODEL_24ebeaf171d0441a95587b23059c1578",
            "value": "Map: 100%"
          }
        },
        "769bed9cc3574b57b5e9e801894f2155": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a87f15420f4bb9a01a6710369751fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5d219a6b02f42e9a6d6899dc5b5df86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9125e6aa1e7462cb5ef0c4a54bfebc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c222e16d7c2a48e4a45e11cc4d7a929d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d293c16207de440699028c2907416c4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3cc5ab24a845f5841507f66db663c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c222e16d7c2a48e4a45e11cc4d7a929d",
            "max": 81379,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9125e6aa1e7462cb5ef0c4a54bfebc8",
            "value": 81379
          }
        },
        "fe33df3b873845c986d5c0da6c26c1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_474acc82aab24f02b52c1238101177aa",
              "IPY_MODEL_da3cc5ab24a845f5841507f66db663c1",
              "IPY_MODEL_2df8bfc7ef894bc0b0665334c35a8f72"
            ],
            "layout": "IPY_MODEL_d293c16207de440699028c2907416c4f"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
